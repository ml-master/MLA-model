# 此文件关于是处理课题数据集的部分

## 1. 预处理数据集文件xx.json
执行process_original_data.py， 将里面的文件名替换成自己的数据集文件名

这里会提取出文本及其对应的标签

## 2. 文档检索
执行 generate_sentence_data.py， 这里根据上一步的生成的每一个文本去检索wiki数据集中最相关的文档句子并保存下来，这个文件格式已经转换好了，可以直接送入mla模型中使用


**(事实上，由于这个文件太大所以这里切分成了三个文件，详见split_origin_sentence.py文件描述)**
## 3. 句子选择
将上一步的文件送入到mla模型后，会得到一个概率文件，这里运行sentence_select_out.py合并处理结果

再运行generate_top_5_sentence.py得到概率最大的五个句子并与声明组合成真实性推理时所需的数据格式

## 4. 结果处理
将上一步的文件送入到mla中的真实性推理脚本中，将得到的概率文件使用eval.py文件计算准确率(eval_2文件强制将结果二分类，eval是三分类)

